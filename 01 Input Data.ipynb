{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03eb6cd5-83c8-4d0b-b434-229b01360416",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pypsa\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "from datetime import timedelta\n",
    "from datetime import datetime, timedelta\n",
    "import calendar\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb5acc7a-3942-4009-905f-0b630f429738",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/19/15zhn_ps157bgm3p882t881h0000gn/T/ipykernel_20714/605421638.py:9: UserWarning:\n",
      "\n",
      "Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to: /Users/qusaialabbassi/Desktop/pythonprojects/Dissertation/Wind Generation/Wind_Generation_Company_2022.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Load the Excel file\n",
    "file_path = '/Users/qusaialabbassi/Desktop/pythonprojects/Dissertation/Wind Generation/Ramboll Data_Wind Generation Data 2022.xlsx'\n",
    "df = pd.read_excel(file_path, skiprows=2)\n",
    "\n",
    "# Rename columns to make them easier to work with\n",
    "df.columns = ['Index', 'Date', 'Daily Total'] + [f'k Wh{i}' for i in range(1, 49)]\n",
    "\n",
    "# Filter the rows for the year 2022\n",
    "df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
    "df = df[df['Date'].dt.year == 2022]\n",
    "\n",
    "# Now, we need to sum the columns as per the provided instructions and reformat the dataframe\n",
    "rows = []\n",
    "for index, row in df.iterrows():\n",
    "    date = row['Date']\n",
    "    for i in range(24):\n",
    "        timestamp = date + pd.Timedelta(hours=i)\n",
    "        wind_power_output = row[f'k Wh{i*2+1}'] + row[f'k Wh{i*2+2}']\n",
    "        rows.append([timestamp, wind_power_output])\n",
    "\n",
    "# Create a new DataFrame with the processed data\n",
    "new_df = pd.DataFrame(rows, columns=['Timestamp', 'Wind Power Output (kW)'])\n",
    "\n",
    "# Remove rows after 2022-12-31 00:00:00\n",
    "new_df = new_df[new_df['Timestamp'] <= '2022-12-31 00:00:00']\n",
    "\n",
    "# Remove the row for 2022-01-01 00:00:00\n",
    "new_df = new_df[new_df['Timestamp'] != '2022-01-01 00:00:00']\n",
    "\n",
    "# Save the new dataframe to an Excel file\n",
    "new_file_path = '/Users/qusaialabbassi/Desktop/pythonprojects/Dissertation/Wind Generation/Wind_Generation_Company_2022.xlsx'\n",
    "new_df.to_excel(new_file_path, index=False)\n",
    "\n",
    "print(f\"Processed data saved to: {new_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "115e3d4f-f0bb-46c6-85c7-8e0045bf4a59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully saved to /Users/qusaialabbassi/Desktop/pythonprojects/Dissertation/Wind Generation/Wind_Generation_Data_Input_2022.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Load the Excel file\n",
    "demand_path = '/Users/qusaialabbassi/Desktop/pythonprojects/Dissertation/Wind Demand/National_Demand_UK_2022.xlsx'\n",
    "demand_df = pd.read_excel(demand_path)\n",
    "\n",
    "# Step 2: Sum the 'ND' values for each pair of SETTLEMENT_PERIOD in each day using the provided method\n",
    "demand_df['SETTLEMENT_DATE'] = pd.to_datetime(demand_df['SETTLEMENT_DATE'])\n",
    "\n",
    "rows = []\n",
    "for date, group in demand_df.groupby('SETTLEMENT_DATE'):\n",
    "    for i in range(24):\n",
    "        timestamp = date + pd.Timedelta(hours=i)\n",
    "        period_1 = i * 2 + 1\n",
    "        period_2 = i * 2 + 2\n",
    "        nd_1 = group.loc[group['SETTLEMENT_PERIOD'] == period_1, 'ND'].values\n",
    "        nd_2 = group.loc[group['SETTLEMENT_PERIOD'] == period_2, 'ND'].values\n",
    "        if nd_1.size > 0 and nd_2.size > 0:\n",
    "            load_demand = nd_1[0] + nd_2[0]\n",
    "            rows.append([timestamp, load_demand])\n",
    "        else:\n",
    "            rows.append([timestamp, None])\n",
    "\n",
    "summed_demand_df = pd.DataFrame(rows, columns=['Timestamp', 'Load Demand (MW)'])\n",
    "\n",
    "# Step 3: Cut all 'Timestamp' after 2022-12-31 00:00:00\n",
    "summed_demand_df = summed_demand_df[summed_demand_df['Timestamp'] <= '2022-12-31 00:00:00']\n",
    "\n",
    "# Step 4: Save the intermediate summed demand data\n",
    "output_summed_demand_path = '/Users/qusaialabbassi/Desktop/pythonprojects/Dissertation/Wind Demand/Demand_UK_2022_Final.xlsx'\n",
    "summed_demand_df.to_excel(output_summed_demand_path, index=False)\n",
    "\n",
    "# Step 5: Load the wind generation data and cut all 'Timestamp' after 2022-12-31 00:00:00\n",
    "wind_gen_path = '/Users/qusaialabbassi/Desktop/pythonprojects/Dissertation/Wind Generation/Wind_Generation_Company_2022.xlsx'\n",
    "wind_gen_df = pd.read_excel(wind_gen_path)\n",
    "wind_gen_df = wind_gen_df[wind_gen_df['Timestamp'] <= '2022-12-31 00:00:00']\n",
    "\n",
    "# Step 6: Convert 'Wind Power Output' from kW to MW\n",
    "wind_gen_df['Wind Power Output (MW)'] = wind_gen_df['Wind Power Output (kW)'] / 1000\n",
    "wind_gen_df.drop(columns=['Wind Power Output (kW)'], inplace=True)\n",
    "\n",
    "# Step 7: Add 'Load Demand (MW)' column to the wind generation data and save the final file\n",
    "# Merge the demand data with the wind generation data on 'Timestamp'\n",
    "final_df = pd.merge(wind_gen_df, summed_demand_df, on='Timestamp', how='left')\n",
    "\n",
    "# Save the final file with specified title heads\n",
    "final_output_path = '/Users/qusaialabbassi/Desktop/pythonprojects/Dissertation/Wind Generation/Wind_Generation_Data_Input_2022.xlsx'\n",
    "final_df.to_excel(final_output_path, index=False, columns=['Timestamp', 'Wind Power Output (MW)', 'Load Demand (MW)'])\n",
    "\n",
    "print(f'Data successfully saved to {final_output_path}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c90bcb1b-3809-4581-95b7-5dd85d834f5c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully saved to /Users/qusaialabbassi/Desktop/pythonprojects/Dissertation/Wind Demand/Demand_UK_2022_Final_for_plot_only.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Load the Excel file\n",
    "demand_path = '/Users/qusaialabbassi/Desktop/pythonprojects/Dissertation/Wind Demand/National_Demand_UK_2022.xlsx'\n",
    "demand_df = pd.read_excel(demand_path)\n",
    "\n",
    "# Step 2: Delete rows with SETTLEMENT_PERIOD in the specified range\n",
    "settlement_periods_to_remove = list(range(1, 48, 2))\n",
    "demand_df = demand_df[~demand_df['SETTLEMENT_PERIOD'].isin(settlement_periods_to_remove)]\n",
    "\n",
    "# Step 3: Keep only the 'ND' column\n",
    "demand_df = demand_df[['ND']]\n",
    "\n",
    "# Step 4: Rename 'ND' to 'Load Demand (MW)'\n",
    "demand_df.rename(columns={'ND': 'Load Demand (MW)'}, inplace=True)\n",
    "\n",
    "# Step 5: Add 'Timestamp' column with hourly intervals starting from 2022-01-01 00:00:00\n",
    "demand_df['Timestamp'] = pd.date_range(start='2022-01-01 01:00:00', periods=len(demand_df), freq='h')\n",
    "demand_df = demand_df[['Timestamp', 'Load Demand (MW)']]\n",
    "\n",
    "# Step 6: Cut all 'Timestamp' after 2022-12-31 00:00:00\n",
    "demand_df = demand_df[demand_df['Timestamp'] <= '2022-12-31 00:00:00']\n",
    "\n",
    "# Step 7: Save the Excel sheet under the specified name and path\n",
    "output_demand_path = '/Users/qusaialabbassi/Desktop/pythonprojects/Dissertation/Wind Demand/Demand_UK_2022_Final_for_plot_only.xlsx'\n",
    "demand_df.to_excel(output_demand_path, index=False)\n",
    "\n",
    "print(f'Data successfully saved to {output_demand_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "294cd984-a63d-4954-9637-be3b43ff3249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to /Users/qusaialabbassi/Desktop/pythonprojects/Dissertation/Electricity Price/Merged_Electricity_Prices_2022.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Elexon API endpoint and API key\n",
    "api_url = 'https://data.elexon.co.uk/bmrs/api/v1/balancing/pricing/market-index'\n",
    "api_key = 't3nj6h9ockem80q'  # Provided API key\n",
    "\n",
    "# Function to fetch data for a specific date range\n",
    "def fetch_data_for_month(year, month):\n",
    "    # Determine the number of days in the month\n",
    "    num_days = calendar.monthrange(year, month)[1]\n",
    "\n",
    "    # Initialize variables\n",
    "    data_all = []\n",
    "\n",
    "    # Headers\n",
    "    headers = {\n",
    "        'accept': 'text/csv',\n",
    "        'x-api-key': api_key}\n",
    "\n",
    "    # Iterate over each week of the month\n",
    "    current_date = datetime(year, month, 1)\n",
    "    while current_date.month == month:\n",
    "        end_date = current_date + timedelta(days=6)\n",
    "        if end_date.month != month:\n",
    "            end_date = datetime(year, month, num_days)\n",
    "\n",
    "        params = {\n",
    "            'from': current_date.strftime('%Y-%m-%dT00:00Z'),\n",
    "            'to': end_date.strftime('%Y-%m-%dT23:59Z'),\n",
    "            'dataProviders': 'APXMIDP',  # Changed from N2EXMIDP to APXMIDP\n",
    "            'format': 'csv'}\n",
    "        try:\n",
    "            # Make GET request\n",
    "            response = requests.get(api_url, params=params, headers=headers)\n",
    "\n",
    "            # Check if request was successful\n",
    "            if response.status_code == 200:\n",
    "                # Append the fetched data to the list\n",
    "                data_all.append(response.text)\n",
    "            else:\n",
    "                print(f\"Error fetching data for {current_date.date()} to {end_date.date()}: {response.status_code} - {response.text}\")\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Error fetching data for {current_date.date()} to {end_date.date()}: {e}\")\n",
    "        current_date = end_date + timedelta(days=1)\n",
    "    return data_all\n",
    "\n",
    "# Function to save data to an Excel file\n",
    "def save_to_excel(data, filename, year):\n",
    "    # Combine all data into a single DataFrame\n",
    "    combined_data = pd.concat([pd.read_csv(StringIO(block)) for block in data], ignore_index=True)\n",
    "    \n",
    "    # Rename the 'StartTime' column to 'Timestamp'\n",
    "    if 'StartTime' in combined_data.columns:\n",
    "        combined_data.rename(columns={'StartTime': 'Timestamp'}, inplace=True)\n",
    "    \n",
    "    # Format the 'Timestamp' column to YYYY-MM-DD HH:MM:SS\n",
    "    if 'Timestamp' in combined_data.columns:\n",
    "        combined_data['Timestamp'] = pd.to_datetime(combined_data['Timestamp']).dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    \n",
    "    # Drop specified columns\n",
    "    columns_to_drop = ['SettlementDate', 'SettlementPeriod', 'Volume']\n",
    "    combined_data.drop(columns=[col for col in columns_to_drop if col in combined_data.columns], inplace=True)\n",
    "    \n",
    "    # Create a complete DataFrame of all possible timestamps for the year up to YYYY-12-31 00:00:00\n",
    "    all_timestamps = pd.date_range(start=f'{year}-01-01 01:00:00', end=f'{year}-12-31 00:00:00', freq='h').strftime('%Y-%m-%d %H:%M:%S')\n",
    "    all_timestamps_df = pd.DataFrame(all_timestamps, columns=['Timestamp'])\n",
    "    \n",
    "    # Merge the combined data with the all timestamps DataFrame\n",
    "    final_data = pd.merge(all_timestamps_df, combined_data, on='Timestamp', how='left')\n",
    "    \n",
    "    # Fill missing data with the value from the previous day at the same hour\n",
    "    for index, row in final_data.iterrows():\n",
    "        if pd.isna(row).any():\n",
    "            prev_day_timestamp = (pd.to_datetime(row['Timestamp']) - timedelta(days=1)).strftime('%Y-%m-%d %H:%M:%S')\n",
    "            prev_day_value = final_data.loc[final_data['Timestamp'] == prev_day_timestamp].drop(columns=['Timestamp'])\n",
    "            if not prev_day_value.empty:\n",
    "                final_data.loc[index, prev_day_value.columns] = prev_day_value.values[0]\n",
    "    \n",
    "    # Rename the price column to 'Price (£/MWh)' if it exists\n",
    "    if 'Price' in final_data.columns:\n",
    "        final_data.rename(columns={'Price': 'Price (£/MWh)'}, inplace=True)\n",
    "    \n",
    "    # Sort the data by 'Timestamp' in ascending order\n",
    "    final_data.sort_values(by='Timestamp', ascending=True, inplace=True)\n",
    "    \n",
    "    # Save to Excel file\n",
    "    final_data.to_excel(filename, index=False)\n",
    "\n",
    "# Example: Fetch data for the entire year and save to Excel file\n",
    "year = 2022\n",
    "all_data = []\n",
    "\n",
    "for month in range(1, 13):\n",
    "    data_for_month = fetch_data_for_month(year, month)\n",
    "    all_data.extend(data_for_month)\n",
    "\n",
    "# Specify the filename to save\n",
    "excel_filename = '/Users/qusaialabbassi/Desktop/pythonprojects/Dissertation/Electricity Price/Merged_Electricity_Prices_2022.xlsx'\n",
    "\n",
    "# Save data to Excel file\n",
    "save_to_excel(all_data, excel_filename, year)\n",
    "\n",
    "print(f\"Data saved to {excel_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c997db6a-24f2-449e-ad81-87136505c4a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 6 electricity prices per day have been saved to /Users/qusaialabbassi/Desktop/pythonprojects/Dissertation/Electricity Price/Top_6_Electricity_Prices_Per_Day_2022.xlsx\n",
      "The most common timestamps with the highest prices are:\n",
      "18:00:00 - 294 occurrences\n",
      "17:00:00 - 258 occurrences\n",
      "19:00:00 - 257 occurrences\n",
      "20:00:00 - 182 occurrences\n",
      "16:00:00 - 166 occurrences\n",
      "07:00:00 - 127 occurrences\n"
     ]
    }
   ],
   "source": [
    "# Load the data from the uploaded Excel file\n",
    "file_path = '/Users/qusaialabbassi/Desktop/pythonprojects/Dissertation/Electricity Price/Merged_Electricity_Prices_2022.xlsx'\n",
    "electricity_prices_df = pd.read_excel(file_path)\n",
    "\n",
    "# Convert the 'Timestamp' column to datetime format\n",
    "electricity_prices_df['Timestamp'] = pd.to_datetime(electricity_prices_df['Timestamp'])\n",
    "\n",
    "# Add a column for the date\n",
    "electricity_prices_df['Date'] = electricity_prices_df['Timestamp'].dt.date\n",
    "\n",
    "# Sort the dataframe by Date and Price in descending order\n",
    "electricity_prices_df_sorted = electricity_prices_df.sort_values(by=['Date', 'Price (£/MWh)'], ascending=[True, False])\n",
    "\n",
    "# Group by Date and take the top 6 prices for each day\n",
    "top_6_prices_per_day = electricity_prices_df_sorted.groupby('Date').head(6).reset_index(drop=True)\n",
    "\n",
    "# Define the file path for the output Excel file\n",
    "output_file_path = '/Users/qusaialabbassi/Desktop/pythonprojects/Dissertation/Electricity Price/Top_6_Electricity_Prices_Per_Day_2022.xlsx'\n",
    "\n",
    "# Save the result to an Excel file\n",
    "top_6_prices_per_day.to_excel(output_file_path, index=False)\n",
    "\n",
    "print(f\"Top 6 electricity prices per day have been saved to {output_file_path}\")\n",
    "\n",
    "# Find the most common timestamps for these highest prices\n",
    "most_common_timestamps = top_6_prices_per_day['Timestamp'].dt.time.value_counts().head(6)\n",
    "\n",
    "# Display the most common timestamps with highest prices\n",
    "print(\"The most common timestamps with the highest prices are:\")\n",
    "for timestamp, count in most_common_timestamps.items():\n",
    "    print(f\"{timestamp} - {count} occurrences\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a325571-cb5c-4610-b8d8-26912a9f2617",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered file saved at /Users/qusaialabbassi/Desktop/pythonprojects/Dissertation/DC Price/Dynamic Containment auction results_filtered.xlsx\n",
      "DCH file saved at /Users/qusaialabbassi/Desktop/pythonprojects/Dissertation/DC Price/Dynamic Containment auction results_filtered_DCH.xlsx\n",
      "DCL file saved at /Users/qusaialabbassi/Desktop/pythonprojects/Dissertation/DC Price/Dynamic Containment auction results_filtered_DCL.xlsx\n"
     ]
    }
   ],
   "source": [
    "def delete_specified_rows(df, values_to_delete):\n",
    "    \"\"\"\n",
    "    Delete all rows that contain any of the specified values.\n",
    "    \"\"\"\n",
    "    return df[~df.isin(values_to_delete).any(axis=1)]\n",
    "\n",
    "def separate_dch_dcl(df):\n",
    "    \"\"\"\n",
    "    Separate the rows containing 'DCH' and 'DCL' into separate DataFrames.\n",
    "    \"\"\"\n",
    "    df_dch = df[df.apply(lambda row: row.astype(str).str.contains('DCH').any(), axis=1)].copy()\n",
    "    df_dcl = df[df.apply(lambda row: row.astype(str).str.contains('DCL').any(), axis=1)].copy()\n",
    "    return df_dch, df_dcl\n",
    "\n",
    "def replace_efa_column(df):\n",
    "    \"\"\"\n",
    "    Replace the EFA column cells with the specified values based on the EFA Date column.\n",
    "    \"\"\"\n",
    "    efa_replacements = {\n",
    "        1: \"00:00:00\",\n",
    "        2: \"07:00:00\",\n",
    "        3: \"11:00:00\",\n",
    "        4: \"15:00:00\",\n",
    "        5: \"19:00:00\",\n",
    "        6: \"23:00:00\"\n",
    "    }\n",
    "    \n",
    "    def get_replacement(row):\n",
    "        efa_date = row['EFA Date'].strftime('%Y-%m-%d')\n",
    "        efa_time = efa_replacements.get(row['EFA'])\n",
    "        return f\"{efa_date} {efa_time}\" if efa_time else row['EFA']\n",
    "    \n",
    "    df['EFA'] = df.apply(get_replacement, axis=1)\n",
    "    return df\n",
    "\n",
    "def rename_and_reorder_columns(df):\n",
    "    \"\"\"\n",
    "    Rename 'EFA' column to 'Timestamp' and 'Cleared Volume' to 'Volume (MW)', and move 'Timestamp' to the first column.\n",
    "    \"\"\"\n",
    "    df.rename(columns={'EFA': 'Timestamp', 'Cleared Volume': 'Volume (MW)'}, inplace=True)\n",
    "    columns = ['Timestamp'] + [col for col in df.columns if col != 'Timestamp']\n",
    "    df = df[columns]\n",
    "    return df\n",
    "\n",
    "def delete_unnecessary_columns(df):\n",
    "    \"\"\"\n",
    "    Delete the 'EFA Date', 'Delivery Start', and 'Delivery End' columns from the DataFrame.\n",
    "    \"\"\"\n",
    "    return df.drop(columns=['EFA Date', 'Delivery Start', 'Delivery End'])\n",
    "\n",
    "def filter_data_for_2022(df):\n",
    "    \"\"\"\n",
    "    Keep only the data for the year 2022.\n",
    "    \"\"\"\n",
    "    df['Timestamp'] = pd.to_datetime(df['Timestamp'])\n",
    "    return df[df['Timestamp'].dt.year == 2022]\n",
    "\n",
    "def insert_empty_rows_and_fill(df, service_type):\n",
    "    \"\"\"\n",
    "    Insert empty rows after specific timestamps and fill 'Service', 'Price (£/MWh)', and 'Volume (MW)' cells.\n",
    "    \"\"\"\n",
    "    empty_rows_after = {\n",
    "        \"00:00:00\": 6,\n",
    "        \"07:00:00\": 3,\n",
    "        \"11:00:00\": 3,\n",
    "        \"15:00:00\": 3,\n",
    "        \"19:00:00\": 3\n",
    "    }\n",
    "    \n",
    "    result_dfs = []\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        result_dfs.append(pd.DataFrame([row]))\n",
    "        timestamp = row['Timestamp'].strftime('%H:%M:%S')\n",
    "        if timestamp in empty_rows_after:\n",
    "            for _ in range(empty_rows_after[timestamp]):\n",
    "                result_dfs.append(pd.DataFrame([{}]))\n",
    "    \n",
    "    result_df = pd.concat(result_dfs, ignore_index=True)\n",
    "    result_df['Service'] = result_df['Service'].ffill()\n",
    "    result_df['Price (£/MWh)'] = result_df['Clearing Price'].ffill()\n",
    "    result_df['Volume (MW)'] = result_df['Volume (MW)'].ffill()\n",
    "    result_df['Service'] = result_df['Service'].fillna(service_type)\n",
    "    \n",
    "    # Fill the 'Timestamp' column in ascending pattern (one hour additional after each cell)\n",
    "    last_timestamp = None\n",
    "    for i, row in result_df.iterrows():\n",
    "        if pd.notna(row['Timestamp']):\n",
    "            last_timestamp = row['Timestamp']\n",
    "        else:\n",
    "            if last_timestamp is not None:\n",
    "                last_timestamp += timedelta(hours=1)\n",
    "                result_df.at[i, 'Timestamp'] = last_timestamp\n",
    "    \n",
    "    return result_df.drop(columns=['Clearing Price'])\n",
    "\n",
    "def delete_rows_after_date(df, cutoff_date):\n",
    "    \"\"\"\n",
    "    Delete all rows after the specified cutoff date.\n",
    "    \"\"\"\n",
    "    cutoff_timestamp = pd.to_datetime(cutoff_date)\n",
    "    return df[df['Timestamp'] <= cutoff_timestamp]\n",
    "\n",
    "def delete_service_column(df):\n",
    "    \"\"\"\n",
    "    Delete the 'Service' column from the DataFrame.\n",
    "    \"\"\"\n",
    "    return df.drop(columns=['Service'])\n",
    "\n",
    "# Define the path to the Excel file\n",
    "file_path = \"/Users/qusaialabbassi/Desktop/pythonprojects/Dissertation/DC Price/Dynamic Containment auction results.xlsx\"\n",
    "\n",
    "# Load the Excel file\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Create a copy of the DataFrame to avoid the SettingWithCopyWarning\n",
    "df = df.copy()\n",
    "\n",
    "# Define the values to delete\n",
    "values_to_delete = ['DMH', 'DML', 'DRH', 'DRL']\n",
    "\n",
    "# Delete rows that contain the specified values\n",
    "df_filtered = delete_specified_rows(df, values_to_delete).copy()\n",
    "\n",
    "# Replace the EFA column values\n",
    "df_filtered = replace_efa_column(df_filtered).copy()\n",
    "\n",
    "# Rename 'EFA' to 'Timestamp' and 'Cleared Volume' to 'Volume (MW)', and reorder columns\n",
    "df_filtered = rename_and_reorder_columns(df_filtered).copy()\n",
    "\n",
    "# Delete the 'EFA Date', 'Delivery Start', and 'Delivery End' columns\n",
    "df_filtered = delete_unnecessary_columns(df_filtered).copy()\n",
    "\n",
    "# Keep only data for 2022\n",
    "df_filtered = filter_data_for_2022(df_filtered).copy()\n",
    "\n",
    "# Separate the rows containing 'DCH' and 'DCL' into separate DataFrames\n",
    "df_dch, df_dcl = separate_dch_dcl(df_filtered)\n",
    "\n",
    "# Insert empty rows and fill cells for DCH\n",
    "df_dch_filled = insert_empty_rows_and_fill(df_dch, 'DCH')\n",
    "\n",
    "# Insert empty rows and fill cells for DCL\n",
    "df_dcl_filled = insert_empty_rows_and_fill(df_dcl, 'DCL')\n",
    "\n",
    "# Delete all rows after 2022-12-31 00:00:00\n",
    "cutoff_date = \"2022-12-31 00:00:00\"\n",
    "df_dch_filled = delete_rows_after_date(df_dch_filled, cutoff_date)\n",
    "df_dcl_filled = delete_rows_after_date(df_dcl_filled, cutoff_date)\n",
    "\n",
    "# Delete the 'Service' column\n",
    "df_dch_filled = delete_service_column(df_dch_filled)\n",
    "df_dcl_filled = delete_service_column(df_dcl_filled)\n",
    "\n",
    "# Define the new file paths\n",
    "filtered_file_path = \"/Users/qusaialabbassi/Desktop/pythonprojects/Dissertation/DC Price/Dynamic Containment auction results_filtered.xlsx\"\n",
    "dch_file_path = \"/Users/qusaialabbassi/Desktop/pythonprojects/Dissertation/DC Price/Dynamic Containment auction results_filtered_DCH.xlsx\"\n",
    "dcl_file_path = \"/Users/qusaialabbassi/Desktop/pythonprojects/Dissertation/DC Price/Dynamic Containment auction results_filtered_DCL.xlsx\"\n",
    "\n",
    "# Save the filtered DataFrame to a new Excel file\n",
    "df_filtered.to_excel(filtered_file_path, index=False)\n",
    "\n",
    "# Save the DCH and DCL DataFrames to separate Excel files\n",
    "df_dch_filled.to_excel(dch_file_path, index=False)\n",
    "df_dcl_filled.to_excel(dcl_file_path, index=False)\n",
    "\n",
    "print(f\"Filtered file saved at {filtered_file_path}\")\n",
    "print(f\"DCH file saved at {dch_file_path}\")\n",
    "print(f\"DCL file saved at {dcl_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d767db2-b581-422c-bd0e-4d0ecb92784b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved to: /Users/qusaialabbassi/Desktop/pythonprojects/Dissertation/DC Price/combined_DC_prices.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Load the Excel files\n",
    "dcl_df = pd.read_excel('/Users/qusaialabbassi/Desktop/pythonprojects/Dissertation/DC Price/DCL_Prices.xlsx')\n",
    "dch_df = pd.read_excel('/Users/qusaialabbassi/Desktop/pythonprojects/Dissertation/DC Price/DCH_Prices.xlsx')\n",
    "\n",
    "# Ensure that the 'Timestamp' columns are in datetime format\n",
    "dcl_df['Timestamp'] = pd.to_datetime(dcl_df['Timestamp'])\n",
    "dch_df['Timestamp'] = pd.to_datetime(dch_df['Timestamp'])\n",
    "\n",
    "# Sort by timestamp just in case\n",
    "dcl_df = dcl_df.sort_values(by='Timestamp')\n",
    "dch_df = dch_df.sort_values(by='Timestamp')\n",
    "\n",
    "# Create a new DataFrame to store the result\n",
    "result_df = pd.DataFrame()\n",
    "\n",
    "# Group by day\n",
    "dcl_grouped = dcl_df.groupby(dcl_df['Timestamp'].dt.date)\n",
    "dch_grouped = dch_df.groupby(dch_df['Timestamp'].dt.date)\n",
    "\n",
    "for date, dcl_day_data in dcl_grouped:\n",
    "    dch_day_data = dch_grouped.get_group(date)\n",
    "    \n",
    "    # Determine the halfway point for each day\n",
    "    halfway_index = len(dcl_day_data) // 2\n",
    "    \n",
    "    # Assign the first half of the day to DCL\n",
    "    first_half = dcl_day_data.iloc[:halfway_index].copy()\n",
    "    first_half['DataProvider'] = 'DCL'\n",
    "    first_half['Price (£/MWh)'] = first_half['Price (£/MWh)']\n",
    "    \n",
    "    # Assign the second half of the day to DCH\n",
    "    second_half = dch_day_data.iloc[halfway_index:].copy()\n",
    "    second_half['DataProvider'] = 'DCH'\n",
    "    second_half['Price (£/MWh)'] = second_half['Price (£/MWh)']\n",
    "    \n",
    "    # Concatenate the two halves\n",
    "    combined_day_data = pd.concat([first_half, second_half])\n",
    "    \n",
    "    # Append to the result DataFrame\n",
    "    result_df = pd.concat([result_df, combined_day_data])\n",
    "\n",
    "# Reset index for the final DataFrame\n",
    "result_df = result_df.reset_index(drop=True)\n",
    "\n",
    "# Save the result to a new Excel file\n",
    "output_path = '/Users/qusaialabbassi/Desktop/pythonprojects/Dissertation/DC Price/combined_DC_prices.xlsx'\n",
    "result_df.to_excel(output_path, index=False)\n",
    "\n",
    "# Print the output file path\n",
    "print(f\"File saved to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e52544-34a8-4a24-a96f-61a624cd1b37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
